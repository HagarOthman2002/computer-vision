# -*- coding: utf-8 -*-
"""intel image classification using CNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fFm8TwkqUz9cRRNF3do8xeaSsEQWgKV4
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
import glob as gb
import tensorflow as tf
import keras
import zipfile
import cv2

from google.colab import drive
drive.mount('/content/drive')

# Path to your zip file
zip_path = '/content/drive/MyDrive/intel image classeification.zip'

# Extract to a specific folder
extract_to = '/content/extracted_files'
os.makedirs(extract_to, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

print("Files extracted to:", extract_to)
!ls {extract_to}

train_path = "/content/extracted_files/seg_train/"
test_path = "/content/extracted_files/seg_test/"
pred_path = "/content/extracted_files/seg_pred/"

for folder in os.listdir(train_path + "seg_train"):
    images = gb.glob(pathname = str(train_path + "seg_train/" + folder + "/*jpg") )
    print(f"for training data , found {len(images)} in folder{folder}")

for folder in os.listdir(test_path + "seg_test"):
    images = gb.glob(pathname = str(test_path + "seg_test/" + folder + "/*jpg"))
    print(f"for testing data , found{len(images)} in folder{folder}")

images = gb.glob(pathname = str(pred_path + "seg_pred/*jpg") )
print(f"for prediction data , found{len(images)} ")

#size of train data
size= []
for folder in os.listdir(train_path + "seg_train"):
    images = gb.glob(pathname = str(train_path + "seg_train/" + folder + "/*jpg") )
    for img in images:
      img = plt.imread(img)
      size.append(img.shape)
pd.Series(size).value_counts()

#size of test data
size= []
for folder in os.listdir(test_path + "seg_test"):
    images = gb.glob(pathname = str(test_path + "seg_test/" + folder + "/*jpg") )
    for img in images:
      img = plt.imread(img)
      size.append(img.shape)
pd.Series(size).value_counts()

#size of prediction data
size= []
images = gb.glob(pathname = str(pred_path + "seg_pred/*jpg") )
for img in images:
      img = plt.imread(img)
      size.append(img.shape)
pd.Series(size).value_counts()

code ={"buildings" : 0 , "forest":1 , "glacier" : 2 , "mountain":3 , "sea" : 4 , "street":5}
def getname(n):
  for k,v in code.items():
    if v==n:
       return k

#read training data
X_train = []
y_train = []
for folder in os.listdir(train_path + "seg_train"):
    images = gb.glob(pathname = str(train_path + "seg_train/" + folder + "/*jpg") )
    for img in images:
      img = cv2.imread(img)
      #resize for images
      img = cv2.resize(img, (100, 100))
      X_train.append(img)   #image itself
      y_train.append(code[folder])              #label of the image

#read test data
X_test = []
y_test = []
for folder in os.listdir(train_path + "seg_train"):
    images = gb.glob(pathname = str(test_path + "seg_test/" + folder + "/*jpg") )
    for img in images:
      img = cv2.imread(img)
      #resize for images
      img = cv2.resize(img, (100, 100))
      X_test.append(img)   #image itself
      y_test.append(code[folder])              #label of the image

#read prediction data
X_pred = []
y_pred = []
images = gb.glob(pathname = str(pred_path + "seg_pred/*jpg") )
for img in images:
      img = cv2.imread(img)
      #resize for images
      img = cv2.resize(img, (100, 100))
      X_pred.append(img)



plt.figure(figsize = (20,20))
for i,v in enumerate (np.random.randint(0,len(X_train) , 36)):
  plt.subplot(6,6,i+1)
  plt.axis("off")
  plt.title(getname(y_train[v]))
  plt.imshow(X_train[v])

X_train = np.array(X_train)
X_test = np.array(X_test)


y_train = np.array(y_train)
y_test = np.array(y_test)

X_pred = np.array(X_pred)

model = keras.models.Sequential(
[
    keras.layers.Conv2D(200 , kernel_size= (3,3) , activation="relu" , input_shape=(100,100,3)),
    keras.layers.Conv2D(120 , kernel_size= (3,3) , activation="relu" ),
    keras.layers.MaxPooling2D(4,4),
    keras.layers.Conv2D(120 , kernel_size= (3,3) , activation="relu" ),
    keras.layers.Conv2D(80 , kernel_size= (3,3) , activation="relu" ),
    keras.layers.Conv2D(50 , kernel_size= (3,3) , activation="relu" ),
    keras.layers.MaxPooling2D(4,4),
    keras.layers.Flatten(),
    keras.layers.Dense(120, activation="relu"),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(500, activation="relu"),
    keras.layers.Dense(6,activation = "softmax")

])

model.compile(optimizer='adam' , loss="sparse_categorical_crossentropy" ,metrics=["accuracy"])

model.summary()

final_model = model.fit(X_train,y_train , epochs=20 , batch_size =64, verbose=1)

loss,accuracy = model.evaluate(X_test,y_test)
print(f"accurcay :  {accuracy} , loss: {loss}" )

